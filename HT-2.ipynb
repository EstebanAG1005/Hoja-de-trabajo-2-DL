{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HOJA DE TRABAJO 2\n",
    "\n",
    "KENNETH GALVEZ 20079\n",
    "\n",
    "JESSICA ORTIZ 20192\n",
    "\n",
    "ESTEBAN ALDANA 20591"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando bibliotecas necesarias\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 - Preparación del conjunto de datos\n",
    "\n",
    "Cargue el conjunto de datos de Iris utilizando bibliotecas como sklearn.datasets. Luego, divida el conjunto de datos\n",
    "en conjuntos de entrenamiento y validación.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargando el conjunto de datos de Iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Dividiendo el conjunto de datos en conjuntos de entrenamiento y validación\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Conviértelos a tensores de PyTorch\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "X_val = torch.FloatTensor(X_val)\n",
    "y_val = torch.LongTensor(y_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 - Arquitectura modelo\n",
    "Cree una red neuronal feedforward simple utilizando nn.Module de PyTorch. Luego, defina capa de entrada, capas\n",
    "ocultas y capa de salida. Después, elija las funciones de activación y el número de neuronas por capa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la arquitectura del modelo\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, regularization):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 16)\n",
    "        self.fc2 = nn.Linear(16, 32)\n",
    "        self.fc3 = nn.Linear(32, output_size)\n",
    "        self.dropout = nn.Dropout(0.2) if regularization == 'Dropout' else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        if self.dropout is not None:\n",
    "            x = self.dropout(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        if self.dropout is not None:\n",
    "            x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de hiperparámetros\n",
    "input_size = X_train.shape[1]\n",
    "output_size = len(torch.unique(y_train))\n",
    "num_epochs = 50\n",
    "learning_rate = 0.01\n",
    "\n",
    "best_accuracy = 0\n",
    "best_combo = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3-4-5 - Funciones de Pérdida - Tecnicas de REgularizacion - Algoritmos de optimizacion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Possible loss functions\n",
    "loss_functions = ['CrossEntropy', 'MSE', 'Poisson']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 6 - Experimentación y Análisis\n",
    "Entrene los modelos con diferentes combinaciones de funciones de pérdida, técnicas de regularización y\n",
    "algoritmos de optimización. Para no complicar esta parte, puede dejar fijo dos de estos parámetros (función de\n",
    "pérdida, técnicas de regularización, algoritmo de optimización) y solamente cambiar uno de ellos. Deben verse al\n",
    "menos 9 combinaciones en total, donde es válido que en una de ellas no haya ninguna técnica de regularización. Si\n",
    "quiere experimentar con más combinaciones se le dará hasta 10% de puntos extra.\n",
    "Para cada combinación registre métricas como precisión, pérdida y alguna otra métrica que considere pertinente\n",
    "(Recuerde lo visto en inteligencia artificial).\n",
    "Visualice las curvas (tanto en precisión, pérdida y la tercera métrica que decidió) de entrenamiento y validación\n",
    "utilizando bibliotecas como matplotlib y/o seaborn. Además, recuerde llevar tracking de los tiempos de ejecución\n",
    "de cada combinación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function: CrossEntropy, Regularization: L1, Optimizer: SGD, Validation Accuracy: 0.36666666666666664\n",
      "Loss function: CrossEntropy, Regularization: L1, Optimizer: Adam, Validation Accuracy: 1.0\n",
      "Loss function: CrossEntropy, Regularization: L1, Optimizer: RMSprop, Validation Accuracy: 0.8333333333333334\n",
      "Loss function: CrossEntropy, Regularization: L2, Optimizer: SGD, Validation Accuracy: 0.36666666666666664\n",
      "Loss function: CrossEntropy, Regularization: L2, Optimizer: Adam, Validation Accuracy: 0.9666666666666667\n",
      "Loss function: CrossEntropy, Regularization: L2, Optimizer: RMSprop, Validation Accuracy: 0.8666666666666667\n",
      "Loss function: CrossEntropy, Regularization: Dropout, Optimizer: SGD, Validation Accuracy: 0.7\n",
      "Loss function: CrossEntropy, Regularization: Dropout, Optimizer: Adam, Validation Accuracy: 1.0\n",
      "Loss function: CrossEntropy, Regularization: Dropout, Optimizer: RMSprop, Validation Accuracy: 0.9\n",
      "Loss function: MSE, Regularization: L1, Optimizer: SGD, Validation Accuracy: 0.7\n",
      "Loss function: MSE, Regularization: L1, Optimizer: Adam, Validation Accuracy: 1.0\n",
      "Loss function: MSE, Regularization: L1, Optimizer: RMSprop, Validation Accuracy: 0.8\n",
      "Loss function: MSE, Regularization: L2, Optimizer: SGD, Validation Accuracy: 0.7333333333333333\n",
      "Loss function: MSE, Regularization: L2, Optimizer: Adam, Validation Accuracy: 0.9666666666666667\n",
      "Loss function: MSE, Regularization: L2, Optimizer: RMSprop, Validation Accuracy: 0.9\n",
      "Loss function: MSE, Regularization: Dropout, Optimizer: SGD, Validation Accuracy: 0.36666666666666664\n",
      "Loss function: MSE, Regularization: Dropout, Optimizer: Adam, Validation Accuracy: 1.0\n",
      "Loss function: MSE, Regularization: Dropout, Optimizer: RMSprop, Validation Accuracy: 0.9666666666666667\n",
      "Loss function: Poisson, Regularization: L1, Optimizer: SGD, Validation Accuracy: 0.36666666666666664\n",
      "Loss function: Poisson, Regularization: L1, Optimizer: Adam, Validation Accuracy: 0.9333333333333333\n",
      "Loss function: Poisson, Regularization: L1, Optimizer: RMSprop, Validation Accuracy: 0.8666666666666667\n",
      "Loss function: Poisson, Regularization: L2, Optimizer: SGD, Validation Accuracy: 0.7\n",
      "Loss function: Poisson, Regularization: L2, Optimizer: Adam, Validation Accuracy: 0.9666666666666667\n",
      "Loss function: Poisson, Regularization: L2, Optimizer: RMSprop, Validation Accuracy: 0.9\n",
      "Loss function: Poisson, Regularization: Dropout, Optimizer: SGD, Validation Accuracy: 0.4666666666666667\n",
      "Loss function: Poisson, Regularization: Dropout, Optimizer: Adam, Validation Accuracy: 1.0\n",
      "Loss function: Poisson, Regularization: Dropout, Optimizer: RMSprop, Validation Accuracy: 0.7333333333333333\n",
      "The best combination was Loss function: CrossEntropy, Regularization: None, Optimizer: Adam with a Validation Accuracy of 1.0\n"
     ]
    }
   ],
   "source": [
    "# Realizar todas las combinaciones posibles\n",
    "for loss_function_name in loss_functions:\n",
    "    for regularization in ['L1', 'L2', 'Dropout']:\n",
    "        for optimizer_name in ['SGD', 'Adam', 'RMSprop']:\n",
    "            \n",
    "            model = SimpleNN(input_size, output_size, regularization=regularization)\n",
    "\n",
    "            # Establecer la función de pérdida\n",
    "            loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "            # Establecer el optimizador\n",
    "            if optimizer_name == 'SGD':\n",
    "                optimizer = optim.SGD(model.parameters(), lr=learning_rate, weight_decay=(1e-4 if regularization == 'L2' else 0))\n",
    "            elif optimizer_name == 'Adam':\n",
    "                optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=(1e-4 if regularization == 'L2' else 0))\n",
    "            elif optimizer_name == 'RMSprop':\n",
    "                optimizer = optim.RMSprop(model.parameters(), lr=learning_rate, weight_decay=(1e-4 if regularization == 'L2' else 0))\n",
    "\n",
    "            # Entrenamiento del modelo\n",
    "            for epoch in range(num_epochs):\n",
    "                model.train()\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(X_train)\n",
    "                loss = loss_function(outputs, y_train)\n",
    "                \n",
    "                # Aplicar regularización L1 si se seleccionó\n",
    "                if regularization == 'L1':\n",
    "                    l1_lambda = 1e-4\n",
    "                    l1_norm = sum(p.abs().sum() for p in model.parameters())\n",
    "                    loss += l1_lambda * l1_norm\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # Validación del modelo\n",
    "            model.eval()\n",
    "            val_outputs = model(X_val)\n",
    "            _, predicted = torch.max(val_outputs, 1)\n",
    "            accuracy = accuracy_score(y_val, predicted)\n",
    "            \n",
    "            print(f'Loss function: {loss_function_name}, Regularization: {regularization}, Optimizer: {optimizer_name}, Validation Accuracy: {accuracy}')\n",
    "            \n",
    "            # Guardar la mejor combinación basada en la precisión de validación\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_combo = (loss_function_name, regularization, optimizer_name)\n",
    "\n",
    "print(f'The best combination was Loss function: {best_combo[0]}, Regularization: {best_combo[1]}, Optimizer: {best_combo[2]} with a Validation Accuracy of {best_accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
